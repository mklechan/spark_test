---
- hosts: spark_worker
  vars:
    spark_version: "1.5.2-bin-hadoop2.6"
    spark_mirror: "http://d3kbcqa49mib13.cloudfront.net"
    spark_conf_dir: "/etc/spark"
    spark_usr_dir: "/usr/lib/spark"
    spark_lib_dir: "/var/lib/spark"
    spark_log_dir: "/var/log/spark"
    spark_run_dir: "/run/spark"
    spark_env_extras: {}

  tasks:
    - name: Create service account for Spark
      user: name=spark
            system=yes
            home={{ spark_lib_dir }}
            shell=/bin/false
            state=present
  
    - name: Ensure Spark configuration directory exists
      file: path="{{ spark_conf_dir }}"
            state=directory
  
    - name: Ensure Spark log and run directories exist
      file: path="{{ item }}"
            owner=spark
            group=spark
            mode=0755
            state=directory
      with_items:
        - "{{ spark_log_dir }}"
        - "{{ spark_run_dir }}"
  
    - name: Download Spark distribution
      get_url: url="{{ spark_mirror }}/spark-{{ spark_version }}.tgz"
               dest="/usr/local/src/spark-{{ spark_version }}.tgz"
  
    - name: Extract Spark distribution
      unarchive: src="/usr/local/src/spark-{{ spark_version }}.tgz"
                 dest="/usr/lib"
                 copy=no
                 creates="/usr/lib/spark-{{ spark_version }}"
  
    - name: Setup Spark distribution symlinks
      file: src="{{ item.src }}"
            dest="{{ item.dest }}"
            state=link
      with_items:
        - { src: "/usr/lib/spark-{{ spark_version }}", dest: "{{ spark_usr_dir }}" }
        - { src: "/usr/lib/spark/conf", dest: "{{ spark_conf_dir }}/conf" }
  
    - name: Create shims for Spark binaries
      template: src=spark-shim.j2
                dest="/usr/bin/{{ item }}"
                mode=0755
      with_items:
        - spark-class
        - spark-shell
        - spark-sql
        - spark-submit
  
    - name: Configure Spark environment
      template: src=spark-env.sh.j2
                dest="{{ spark_conf_dir }}/conf/spark-env.sh"
